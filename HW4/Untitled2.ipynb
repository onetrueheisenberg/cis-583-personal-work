{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9b656-626d-4518-aee8-9403be54cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Force CPU mode\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# --- Margin Loss ---\n",
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, pos_score, neg_score):\n",
    "        return torch.mean(F.relu(self.margin - pos_score + neg_score))\n",
    "\n",
    "# --- MLP Class ---\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, n_hidden=1, hidden_size=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        for _ in range(n_hidden - 1):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output(x).squeeze(-1)\n",
    "\n",
    "# --- DeepTripletModel ---\n",
    "class DeepTripletModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, user_dim=64, item_dim=64, margin=1., \n",
    "                 n_hidden=1, hidden_size=64, dropout=0):\n",
    "        super().__init__()\n",
    "        self.user_layer = nn.Embedding(n_users, user_dim)\n",
    "        self.item_layer = nn.Embedding(n_items, item_dim)\n",
    "        self.mlp = MLP(input_dim=user_dim, n_hidden=n_hidden, hidden_size=hidden_size, dropout=dropout)\n",
    "        self.margin_loss = MarginLoss(margin)\n",
    "\n",
    "    def forward(self, user, item_pos, item_neg):\n",
    "        user_emb = F.normalize(self.user_layer(user), dim=1)\n",
    "        item_pos_emb = F.normalize(self.item_layer(item_pos), dim=1)\n",
    "        item_neg_emb = F.normalize(self.item_layer(item_neg), dim=1)\n",
    "\n",
    "        pos_score = self.mlp(user_emb * item_pos_emb)\n",
    "        neg_score = self.mlp(user_emb * item_neg_emb)\n",
    "\n",
    "        loss = self.margin_loss(pos_score, neg_score)\n",
    "        return loss\n",
    "\n",
    "# --- DeepMatchModel ---\n",
    "class DeepMatchModel(nn.Module):\n",
    "    def __init__(self, user_layer, item_layer, mlp):\n",
    "        super().__init__()\n",
    "        self.user_layer = user_layer\n",
    "        self.item_layer = item_layer\n",
    "        self.mlp = mlp\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_layer(user)\n",
    "        item_emb = self.item_layer(item)\n",
    "        return self.mlp(user_emb * item_emb)\n",
    "\n",
    "# --- Manual ROC AUC ---\n",
    "def manual_roc_auc(y_true, y_score):\n",
    "    desc_score_indices = np.argsort(-y_score)\n",
    "    y_true = np.array(y_true)[desc_score_indices]\n",
    "    y_score = np.array(y_score)[desc_score_indices]\n",
    "    pos_count = np.sum(y_true)\n",
    "    neg_count = len(y_true) - pos_count\n",
    "    if pos_count == 0 or neg_count == 0:\n",
    "        return None\n",
    "    cum_pos = np.cumsum(y_true)\n",
    "    cum_neg = np.cumsum(1 - y_true)\n",
    "    tpr = cum_pos / pos_count\n",
    "    fpr = cum_neg / neg_count\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "    return auc\n",
    "\n",
    "def manual_average_roc_auc(model, test_data, n_items):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    for user in test_data:\n",
    "        pos_items = test_data[user]\n",
    "        if not pos_items:\n",
    "            continue\n",
    "        all_items = list(range(n_items))\n",
    "        user_tensor = torch.tensor([user] * len(all_items)).to(device)\n",
    "        item_tensor = torch.tensor(all_items).to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(user_tensor, item_tensor).cpu().numpy()\n",
    "        labels = np.isin(all_items, pos_items).astype(int)\n",
    "        if len(set(labels)) < 2:\n",
    "            continue\n",
    "        auc = manual_roc_auc(labels, predictions)\n",
    "        if auc is not None:\n",
    "            scores.append(auc)\n",
    "    return np.mean(scores) if scores else 0\n",
    "\n",
    "# --- Load Implicit Data ---\n",
    "def load_implicit_data():\n",
    "    df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    df = df.drop(columns=['timestamp'])\n",
    "    df['user_id'] -= 1\n",
    "    df['item_id'] -= 1\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    def build_dict(df):\n",
    "        data = {}\n",
    "        for row in df.itertuples():\n",
    "            data.setdefault(row.user_id, []).append(row.item_id)\n",
    "        return data\n",
    "    return build_dict(train_df), build_dict(test_df)\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train_deep_recsys():\n",
    "    train_data, test_data = load_implicit_data()\n",
    "    n_users = max(max(train_data.keys()), max(test_data.keys())) + 1\n",
    "    n_items = max(max([max(v) for v in train_data.values()]), max([max(v) for v in test_data.values()])) + 1\n",
    "    model = DeepTripletModel(n_users=n_users, n_items=n_items, user_dim=32, item_dim=32, margin=2.0,\n",
    "                              n_hidden=2, hidden_size=128, dropout=0.3).to(device)\n",
    "    match_model = DeepMatchModel(model.user_layer, model.item_layer, model.mlp).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    def sample_triplets(data):\n",
    "        users, pos_items, neg_items = [], [], []\n",
    "        for user, items in data.items():\n",
    "            for _ in range(len(items)):\n",
    "                pos = np.random.choice(items)\n",
    "                neg = np.random.randint(0, n_items)\n",
    "                while neg in items:\n",
    "                    neg = np.random.randint(0, n_items)\n",
    "                users.append(user)\n",
    "                pos_items.append(pos)\n",
    "                neg_items.append(neg)\n",
    "        return (torch.tensor(users).to(device),\n",
    "                torch.tensor(pos_items).to(device),\n",
    "                torch.tensor(neg_items).to(device))\n",
    "\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        user, pos, neg = sample_triplets(train_data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(user, pos, neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        auc = manual_average_roc_auc(match_model, test_data, n_items)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}, ROC AUC: {auc:.4f}\")\n",
    "\n",
    "# --- Run Training ---\n",
    "train_deep_recsys()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
