{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3JqWpRePJUL"
   },
   "source": [
    "Dataset:\n",
    "Digits: 10 class handwritten digits\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "pRYUaCAJPBSU",
    "outputId": "22224965-6f68-4644-86ef-d2bbe39f375f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits = load_digits()\n",
    "digits.images.shape\n",
    "digits.data.shape\n",
    "digits.target.shape\n",
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(digits.images[sample_index], cmap=plt.cm.gray_r,\n",
    "           interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % digits.target[sample_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UktXn-_9PIe1"
   },
   "source": [
    "Train / Test Split\n",
    "\n",
    "Let's keep some held-out data to be able to measure the generalization performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sy4282GoPZbw",
    "outputId": "cbf1cd28-c344-4950-b620-33511402e622"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = np.asarray(digits.data, dtype='float32')\n",
    "target = np.asarray(digits.target, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.15, random_state=37)\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAJ0MRyJPcR6"
   },
   "source": [
    "Preprocessing of the Input Data:\n",
    "\n",
    "Make sure that all input variables are approximately on the same scale via input normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utK4htRKPe39",
    "outputId": "e2b15aed-6d3d-4452-cbdd-4bfaae3a1828"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(scaler.mean_)\n",
    "# print(scaler.scale_)\n",
    "X_train.shape\n",
    "X_train.mean(axis=0)\n",
    "X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACeKDJdNPzDK"
   },
   "source": [
    "Let's display the one of the transformed sample (after feature standardization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "E95kwWDwPv4S",
    "outputId": "d92005ad-dd65-498a-d3b2-17ec877be96b"
   },
   "outputs": [],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_train[sample_index].reshape(8, 8),\n",
    "           cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"transformed sample\\n(standardization)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJHYlCJfP6WW"
   },
   "source": [
    "The scaler objects makes it possible to recover the original sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "bCR0H_BzP6DA",
    "outputId": "f5c2e50a-8c51-4d80-a8b4-6ad52018088a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "sample_data = X_train[sample_index].reshape(1, -1)\n",
    "transformed_sample = scaler.inverse_transform(sample_data)\n",
    "plt.imshow(transformed_sample.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"Original Sample\");\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4enCqNZjQ6TY"
   },
   "source": [
    "Preprocessing of the Target Data\n",
    "\n",
    "To train a first neural network we also need to turn the target variable into a vector \"one-hot-encoding\" representation. Here are the labels of the first samples in the training set encoded as integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bchxw_KPPxPs",
    "outputId": "cd2190d0-e683-4a79-8c8f-aaf765e68ab6"
   },
   "outputs": [],
   "source": [
    "y_train[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5jpwBOeRAWA"
   },
   "source": [
    "Keras provides a utility function to convert integer-encoded categorical variables as one-hot encoded values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O43mL1f-RB_c",
    "outputId": "748470a2-96eb-4d5a-c2ae-dbe09938fd50"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_train[:3]\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyJKcPQaRJQa"
   },
   "source": [
    "Feed Forward Neural Networks with Keras\n",
    "\n",
    "Objectives of this section:\n",
    "\n",
    "Build and train a first feedforward network using Keras\n",
    "https://www.tensorflow.org/guide/keras/overview\n",
    "\n",
    "Experiment with different optimizers, activations, size of layers, initializations\n",
    "\n",
    "A First Keras Model\n",
    "\n",
    "We can now build an train a our first feed forward neural network using the high level API from keras:\n",
    "\n",
    "first we define the model by stacking layers with the right dimensions,\n",
    "then we define a loss function and plug the SGD optimizer,\n",
    "then we feed the model the training data for fixed number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwff8glkRQHT",
    "outputId": "00771524-3348-4845-cf7a-ff21eb00a823"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = Y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
    "model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(learning_rate=0.1),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsO3BMbHRWyH"
   },
   "source": [
    "Visualizing the Convergence\n",
    "\n",
    "Let's wrap the keras history info into a pandas dataframe for easier plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "aVykVumFRg-o",
    "outputId": "e16e81f3-4610-4355-c52b-0112aa66d534"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[\"epoch\"] = history.epoch\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(12, 6))\n",
    "history_df.plot(x=\"epoch\", y=[\"loss\", \"val_loss\"], ax=ax0)\n",
    "history_df.plot(x=\"epoch\", y=[\"accuracy\", \"val_accuracy\"], ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL1lKKNaRjVe"
   },
   "source": [
    "Monitoring Convergence with Tensorboard\n",
    "\n",
    "Tensorboard is a built-in neural network monitoring tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ewJrfc-YRizc",
    "outputId": "66fb1e7b-4a6e-48ce-d96a-13013ce0466a"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "!rm -rf tensorboard_logs\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
    "model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "timestamp =  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"tensorboard_logs/\" + timestamp\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=X_train, y=Y_train, validation_split=0.2, epochs=15,\n",
    "          callbacks=[tensorboard_callback]);\n",
    "%tensorboard --logdir tensorboard_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
