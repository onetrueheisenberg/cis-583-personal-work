{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735a02b-7020-4f29-9290-b6ed61733c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GurmukhiDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform = None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_set = []\n",
    "        self.transform = transform\n",
    "        for class_name in os.listdir(data_dir):\n",
    "            class_path = os.path.join(self.data_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    self.image_set.append((os.path.join(class_path, img_file), int(class_name)))\n",
    "    def __len__(self):\n",
    "        return len(self.image_set)\n",
    "    def __getitem__(self, index):\n",
    "        image_name, label = self.image_set[index]\n",
    "        image = Image.open(image_name).convert('L')\n",
    "        label = int(os.path.basename(os.path.dirname(image_name)))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "root_dir = '/Users/sundarasubramanian/yoyo/CIS-583/HW3/Q2_GurMukhi/GurNum/'\n",
    "transform = transforms.Compose([transforms.Resize((28, 28)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = GurmukhiDataset(data_dir = f\"{root_dir}train/\", transform = transform)\n",
    "test_dataset = GurmukhiDataset(data_dir = f\"{root_dir}val/\", transform = transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "def l1_regularization(model, lambda_l1=0.001):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "    return lambda_l1 * l1_norm\n",
    "def l2_regularization(model, lambda_l2=0.001):\n",
    "    l2_norm = sum((p ** 2).sum() for p in model.parameters())\n",
    "    return lambda_l2 * l2_norm\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # self.dropout = self.dropout_manual(0.5)\n",
    "    def forward(self, x):\n",
    "        x = self.max_pool(self.relu(self.conv1(x)))\n",
    "        x = self.max_pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    def dropout_manual(self, x, dropout_prob=0.5):\n",
    "        if self.training:  # Apply dropout only during training\n",
    "            mask = (torch.rand(x.shape, device=x.device) > dropout_prob).float()\n",
    "            x = x * mask / (1 - dropout_prob)  # Scale activations\n",
    "        return x\n",
    "\n",
    "def gradient_checking(model, X, y, epsilon=1e-5):\n",
    "    grad_diffs = []\n",
    "    param_names = []\n",
    "\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute actual gradients via backprop\n",
    "    X, y = X.to(torch.float32), y.to(torch.long)\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            param_data = param.data.clone()\n",
    "            grad_approx = torch.zeros_like(param)\n",
    "\n",
    "            for i in range(param.numel()):\n",
    "                param.data.view(-1)[i] += epsilon\n",
    "                loss1 = criterion(model(X), y).item()\n",
    "\n",
    "                param.data.view(-1)[i] -= 2 * epsilon\n",
    "                loss2 = criterion(model(X), y).item()\n",
    "\n",
    "                grad_approx.view(-1)[i] = (loss1 - loss2) / (2 * epsilon)\n",
    "                param.data = param_data  # Reset parameter\n",
    "            \n",
    "            if param.grad is not None:\n",
    "                grad_diff = torch.norm(param.grad - grad_approx) / (torch.norm(param.grad + grad_approx) + 1e-7)\n",
    "                grad_diffs.append(grad_diff.item())\n",
    "                param_names.append(name)\n",
    "\n",
    "    # Plot Gradient Differences\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(param_names, grad_diffs, color='skyblue')\n",
    "    plt.xlabel(\"Gradient Difference\")\n",
    "    plt.ylabel(\"Model Parameters\")\n",
    "    plt.title(\"Gradient Checking Differences for Each Parameter\")\n",
    "    plt.show()\n",
    "\n",
    "model = NN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.01)\n",
    "\n",
    "epochs = 1\n",
    "losses = []\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        print('asld,las,d')\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss += l1_regularization(model) + l2_regularization(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "        # Run Gradient Checking on a small batch\n",
    "        X_sample, y_sample = next(iter(train_loader))\n",
    "        gradient_checking(model, X_sample, y_sample)\n",
    "    \n",
    "    avg_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1} / {epochs}; Loss: {loss.item():.4f}\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    print(f\"Epoch: {epoch + 1} / {epochs}; Test Loss: {avg_test_loss:.4f}\")\n",
    "    if epoch == 0: #only run gradient check at the first epoch.\n",
    "        X_sample, y_sample = next(iter(train_loader))\n",
    "        gradient_checking(model, X_sample, y_sample)\n",
    "\n",
    "plt.plot(range(1, epochs+1), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Training vs Test Loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, epochs + 1), test_losses, label=\"Test Loss\", linestyle=\"--\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe4fc5-b204-4a8f-9289-cac04b0ad950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GurmukhiDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform = None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_set = []\n",
    "        self.transform = transform\n",
    "        for class_name in os.listdir(data_dir):\n",
    "            class_path = os.path.join(self.data_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    self.image_set.append((os.path.join(class_path, img_file), int(class_name)))\n",
    "    def __len__(self):\n",
    "        return len(self.image_set)\n",
    "    def __getitem__(self, index):\n",
    "        image_name, label = self.image_set[index]\n",
    "        image = Image.open(image_name).convert('L')\n",
    "        label = int(os.path.basename(os.path.dirname(image_name)))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9512c9-098e-4f0a-a3ee-14f9a6dd1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/sundarasubramanian/yoyo/CIS-583/HW3/Q2_GurMukhi/GurNum/'\n",
    "transform = transforms.Compose([transforms.Resize((28, 28)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = GurmukhiDataset(data_dir = f\"{root_dir}train/\", transform = transform)\n",
    "test_dataset = GurmukhiDataset(data_dir = f\"{root_dir}val/\", transform = transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "def l1_regularization(model, lambda_l1=0.001):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "    return lambda_l1 * l1_norm\n",
    "def l2_regularization(model, lambda_l2=0.001):\n",
    "    l2_norm = sum((p ** 2).sum() for p in model.parameters())\n",
    "    return lambda_l2 * l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0b6a7-a976-4877-b2f3-c6a4787daa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # self.dropout = self.dropout_manual(0.5)\n",
    "    def forward(self, x):\n",
    "        x = self.max_pool(self.relu(self.conv1(x)))\n",
    "        x = self.max_pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    def dropout_manual(self, x, dropout_prob=0.5):\n",
    "        if self.training:  # Apply dropout only during training\n",
    "            mask = (torch.rand(x.shape, device=x.device) > dropout_prob).float()\n",
    "            x = x * mask / (1 - dropout_prob)  # Scale activations\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6971c5-2ee3-4c04-834d-2fba40d5df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_checking(model, X, y, epsilon=1e-5):\n",
    "    grad_diffs = []\n",
    "    param_names = []\n",
    "\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute actual gradients via backprop\n",
    "    X, y = X.to(torch.float32), y.to(torch.long)\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            param_data = param.data.clone()\n",
    "            grad_approx = torch.zeros_like(param)\n",
    "\n",
    "            for i in range(param.numel()):\n",
    "                param.data.view(-1)[i] += epsilon\n",
    "                loss1 = criterion(model(X), y).item()\n",
    "\n",
    "                param.data.view(-1)[i] -= 2 * epsilon\n",
    "                loss2 = criterion(model(X), y).item()\n",
    "\n",
    "                grad_approx.view(-1)[i] = (loss1 - loss2) / (2 * epsilon)\n",
    "                param.data = param_data  # Reset parameter\n",
    "            \n",
    "            if param.grad is not None:\n",
    "                grad_diff = torch.norm(param.grad - grad_approx) / (torch.norm(param.grad + grad_approx) + 1e-7)\n",
    "                grad_diffs.append(grad_diff.item())\n",
    "                param_names.append(name)\n",
    "\n",
    "    # Plot Gradient Differences\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(param_names, grad_diffs, color='skyblue')\n",
    "    plt.xlabel(\"Gradient Difference\")\n",
    "    plt.ylabel(\"Model Parameters\")\n",
    "    plt.title(\"Gradient Checking Differences for Each Parameter\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78aed57-a9e7-404c-81b2-3cc6e88a020d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.01)\n",
    "\n",
    "epochs = 1\n",
    "losses = []\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        print('asld,las,d')\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss += l1_regularization(model) + l2_regularization(model)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "        # Run Gradient Checking on a small batch\n",
    "        X_sample, y_sample = next(iter(train_loader))\n",
    "        gradient_checking(model, X_sample, y_sample)\n",
    "    \n",
    "    avg_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1} / {epochs}; Loss: {loss.item():.4f}\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    print(f\"Epoch: {epoch + 1} / {epochs}; Test Loss: {avg_test_loss:.4f}\")\n",
    "    if epoch == 0: #only run gradient check at the first epoch.\n",
    "        X_sample, y_sample = next(iter(train_loader))\n",
    "        gradient_checking(model, X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb86350-8585-4fa3-b0f6-e590fb45705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy of prediction: {100 * correct / total: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5051be6-75c8-4eb6-8d08-4305230f258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8d21b-c096-4c93-8c97-c26ac0256b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training vs Test Loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, epochs + 1), test_losses, label=\"Test Loss\", linestyle=\"--\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88df23-3f86-48ee-889b-0f8d0417464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# class GurmukhiDataset(Dataset):\n",
    "#     def __init__(self, data_dir, transform=None):\n",
    "#         self.data_dir = data_dir\n",
    "#         self.image_set = []\n",
    "#         self.transform = transform\n",
    "#         for class_name in os.listdir(data_dir):\n",
    "#             class_path = os.path.join(self.data_dir, class_name)\n",
    "#             if os.path.isdir(class_path):\n",
    "#                 for img_file in os.listdir(class_path):\n",
    "#                     self.image_set.append((os.path.join(class_path, img_file), int(class_name)))\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_set)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         image_name, label = self.image_set[index]\n",
    "#         image = Image.open(image_name).convert('L')\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, label\n",
    "\n",
    "# root_dir = '/Users/sundarasubramanian/yoyo/CIS-583/HW3/Q2_GurMukhi/GurNum/'\n",
    "# transform = transforms.Compose([transforms.Resize((28, 28)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# train_dataset = GurmukhiDataset(data_dir=f\"{root_dir}train/\", transform=transform)\n",
    "# test_dataset = GurmukhiDataset(data_dir=f\"{root_dir}val/\", transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def l1_regularization(model, lambda_l1=0.001):\n",
    "#     return lambda_l1 * sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "# def l2_regularization(model, lambda_l2=0.001):\n",
    "#     return lambda_l2 * sum((p ** 2).sum() for p in model.parameters())\n",
    "\n",
    "# class NN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NN, self).__init__()\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "#         self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.max_pool(self.relu(self.conv1(x)))\n",
    "#         x = self.max_pool(self.relu(self.conv2(x)))\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# def gradient_checking(model, X, y, epsilon=1e-5):\n",
    "#     grad_diffs = []\n",
    "#     param_names = []\n",
    "\n",
    "#     model.eval()\n",
    "#     X, y = X.to(torch.float32), y.to(torch.long)\n",
    "#     outputs = model(X)\n",
    "#     loss = criterion(outputs, y)\n",
    "#     model.zero_grad()\n",
    "#     loss.backward()\n",
    "\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if param.requires_grad:\n",
    "#             param_data = param.data.clone()\n",
    "#             grad_approx = torch.zeros_like(param)\n",
    "\n",
    "#             for i in range(param.numel()):\n",
    "#                 param.data.view(-1)[i] += epsilon\n",
    "#                 loss1 = criterion(model(X), y).item()\n",
    "\n",
    "#                 param.data.view(-1)[i] -= 2 * epsilon\n",
    "#                 loss2 = criterion(model(X), y).item()\n",
    "\n",
    "#                 grad_approx.view(-1)[i] = (loss1 - loss2) / (2 * epsilon)\n",
    "#                 param.data = param_data\n",
    "\n",
    "#             if param.grad is not None:\n",
    "#                 grad_diff = torch.norm(param.grad - grad_approx) / (torch.norm(param.grad + grad_approx) + 1e-7)\n",
    "#                 grad_diffs.append(grad_diff.item())\n",
    "#                 param_names.append(name)\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.barh(param_names, grad_diffs, color='skyblue')\n",
    "#     plt.xlabel(\"Gradient Difference\")\n",
    "#     plt.ylabel(\"Model Parameters\")\n",
    "#     plt.title(\"Gradient Checking Differences for Each Parameter\")\n",
    "#     plt.show()\n",
    "\n",
    "# model = NN().to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# epochs = 10\n",
    "# losses = []\n",
    "# train_losses, test_losses = [], []\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     epoch_train_loss = 0\n",
    "\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss += l1_regularization(model) + l2_regularization(model)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_train_loss += loss.item()\n",
    "\n",
    "#     avg_loss = epoch_train_loss / len(train_loader)\n",
    "#     train_losses.append(avg_loss)\n",
    "#     losses.append(avg_loss)\n",
    "\n",
    "#     print(f\"Epoch: {epoch + 1} / {epochs}; Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in test_loader:\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item()\n",
    "    \n",
    "#     avg_test_loss = test_loss / len(test_loader)\n",
    "#     test_losses.append(avg_test_loss)\n",
    "\n",
    "#     print(f\"Epoch: {epoch + 1} / {epochs}; Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "#     if epoch == 0:\n",
    "#         X_sample, y_sample = next(iter(train_loader))\n",
    "#         X_sample, y_sample = X_sample.to(device), y_sample.to(device)\n",
    "#         gradient_checking(model, X_sample, y_sample)\n",
    "\n",
    "# plt.plot(range(1, epochs+1), losses)\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training Loss Curve\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\")\n",
    "# plt.plot(range(1, epochs + 1), test_losses, label=\"Test Loss\", linestyle=\"--\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Train vs Test Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
