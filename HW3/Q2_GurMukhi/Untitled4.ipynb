{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "242a8d30-e930-48e6-b4b5-21074bc62f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image size: 32x32, input_dim: 1024\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# input_shape = (1, height, width) # Since it's grayscale (1 channel)\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m model \u001b[38;5;241m=\u001b[39m GurmukhiNN(input_shape, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# model = GurmukhiNN(input_dim, output_dim, dropout_prob)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[925]:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# In[926]:\n",
    "# Taking sample image to measure dimensions\n",
    "sample_image_path = '/Users/sundarasubramanian/yoyo/CIS-583/HW3/Q2_GurMukhi/GurNum/train/0/1.bmp'\n",
    "sample_image = Image.open(sample_image_path)\n",
    "width, height = sample_image.size\n",
    "input_dim = width * height\n",
    "print(f\"Sample image size: {width}x{height}, input_dim: {input_dim}\")\n",
    "print(sample_image.mode)\n",
    "#Show sample image\n",
    "plt.imshow(sample_image)\n",
    "plt.show()\n",
    "# In[928]:\n",
    "class GurmukhiNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_prob):\n",
    "        super(GurmukhiNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_output_size = (height // 4) * (width // 4) * 64\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # Input: [B, 1, H, W]\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Compute correct input size for FC layer\n",
    "        conv_output_size = 4096 # After 2 pooling layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fco = nn.Linear(64, output_dim)\n",
    "        self.dropout_prob = dropout_prob\n",
    "    def forward(self, x):\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        # Manual dropout calculation\n",
    "        if self.training:\n",
    "            mask = (torch.rand(x.shape, device=x.device) >\n",
    "            self.dropout_prob).float()\n",
    "            x = x * mask / (1.0 - self.dropout_prob)\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "# In[927]:\n",
    "# Preprocessing the dataset\n",
    "transform = transforms.Compose([\n",
    "transforms.Grayscale(num_output_channels=1),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Replace with actual dataset folder\n",
    "train_dataset = datasets.ImageFolder(root='/Users/sundarasubramanian/yoyo/CIS-583/HW3/Q2_GurMukhi/GurNum/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='/Users/sundarasubramanian/yoyo/CIS-583/HW3/Q2_GurMukhi/GurNum/val', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "output_dim = 10 # For digits 0-9\n",
    "num_epochs= 10\n",
    "dropout_prob = 0.4\n",
    "# input_shape = (1, height, width) # Since it's grayscale (1 channel)\n",
    "model = GurmukhiNN(input_shape, output_dim=10, dropout_prob=0.4)\n",
    "# model = GurmukhiNN(input_dim, output_dim, dropout_prob)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "images, labels = next(dataiter)\n",
    "# In[929]:\n",
    "def compute_loss(model, output, target, lambda_l1=0.0, lambda_l2=0.0):\n",
    "    # Manual loss calculation and L1, L2 regularization\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(output, target)\n",
    "    l1_reg = sum(p.abs().sum() for p in model.parameters())\n",
    "    l2_reg = sum((p ** 2).sum() for p in model.parameters())\n",
    "    loss = loss + lambda_l1 * l1_reg + lambda_l2 * l2_reg\n",
    "    return loss\n",
    "# In[930]:\n",
    "# L1, L2, regularization methods\n",
    "def l1_regularization(model, lambda_l1=0.001):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "    return lambda_l1 * l1_norm\n",
    "def l2_regularization(model, lambda_l2=0.001):\n",
    "    l2_norm = sum((p ** 2).sum() for p in model.parameters())\n",
    "    return lambda_l2 * l2_norm\n",
    "# In[931]:\n",
    "# Evaluate and plot accuracy\n",
    "def evaluate_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return 100 * correct / total\n",
    "# In[932]:\n",
    "# train and test with manual gradient checking and plotting\n",
    "# train and test with manual gradient checking and plotting\n",
    "def train_model_with_manual_grad_check(model, train_loader, test_loader, optimizer, \n",
    "                                       l1_lambda=0.0, l2_lambda=0.0, epsilon=1e-5):\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    grad_norm_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        batch_grad_norms = []\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = compute_loss(model, outputs, targets, l1_lambda, l2_lambda)\n",
    "            loss.backward()\n",
    "\n",
    "            # Manual Gradient Checking\n",
    "            manual_grad_norm =0.0\n",
    "            for param in model.parameters():\n",
    "                if param.requires_grad:\n",
    "                    param_data = param.data.clone()\n",
    "                    grad = torch.zeros_like(param)\n",
    "\n",
    "                    for i in range(param.numel()):\n",
    "                        param_data_flat = param_data.view(-1)\n",
    "\n",
    "                        # Compute f(x + epsilon)\n",
    "                        param_data_flat[i] += epsilon\n",
    "                        model.zero_grad()\n",
    "                        outputs_plus = model(inputs)\n",
    "                        loss_plus = compute_loss(model, outputs_plus, targets, l1_lambda, l2_lambda)\n",
    "\n",
    "                        # Compute f(x - epsilon)\n",
    "                        param_data_flat[i] -= 2 * epsilon\n",
    "                        model.zero_grad()\n",
    "                        outputs_minus = model(inputs)\n",
    "                        loss_minus = compute_loss(model, outputs_minus, targets, l1_lambda, l2_lambda)\n",
    "\n",
    "                        # Compute gradient\n",
    "                        grad.view(-1)[i] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "\n",
    "                        # Restore original value\n",
    "                        param_data_flat[i] += epsilon\n",
    "\n",
    "                    manual_grad_norm += torch.norm(grad).item() ** 2\n",
    "            manual_grad_norm = manual_grad_norm ** 0.5\n",
    "            batch_grad_norms.append(manual_grad_norm)\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_grad_norm = sum(batch_grad_norms) / len(batch_grad_norms)\n",
    "        grad_norm_list.append(avg_grad_norm)\n",
    "        train_acc = evaluate_accuracy(model, train_loader)\n",
    "        test_acc = evaluate_accuracy(model, test_loader)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%, Grad Norm: {avg_grad_norm:.4f}\")\n",
    "    \n",
    "    return train_acc_list, test_acc_list, grad_norm_list\n",
    "# In[933]:\n",
    "print(\"Training with L2 regularization (位2=0.001)\")\n",
    "train_acc, test_acc, grad_norms = train_model_with_plots(\n",
    "model, train_loader, test_loader, optimizer, l1_lambda=0.0, l2_lambda=0.001\n",
    ")\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc, label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training and Test Accuracy\")\n",
    "plt.legend()\n",
    "# Plot Gradient Norms\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, grad_norms, 'r-', label='Avg Gradient Norm')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Gradient Norm\")\n",
    "plt.title(\"Average Gradient Norm per Epoch\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# In[934]:\n",
    "print(\"Training with L1 regularization (位1=0.001)\")\n",
    "train_acc, test_acc, grad_norms = train_model_with_plots(\n",
    "model, train_loader, test_loader, optimizer, l1_lambda=0.001, l2_lambda=0.0\n",
    ")\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc, label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training and Test Accuracy\")\n",
    "plt.legend()\n",
    "# Plot Gradient Norms\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, grad_norms, 'r-', label='Avg Gradient Norm')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Gradient Norm\")\n",
    "plt.title(\"Average Gradient Norm per Epoch\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# In[935]:\n",
    "print(\"Training with Dropout regularization\")\n",
    "train_acc, test_acc, grad_norms = train_model_with_plots(\n",
    "model, train_loader, test_loader, optimizer, l1_lambda=0.0, l2_lambda=0.0\n",
    ")\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc, label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training and Test Accuracy\")\n",
    "plt.legend()\n",
    "# Plot Gradient Norms\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, grad_norms, 'r-', label='Avg Gradient Norm')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Gradient Norm\")\n",
    "plt.title(\"Average Gradient Norm per Epoch\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# In[936]:\n",
    "print(\"Training with L1, L2, Dropout regularization (位1=0.001, 位2=0.001)\")\n",
    "train_acc, test_acc, grad_norms = train_model_with_plots(\n",
    "model, train_loader, test_loader, optimizer, l1_lambda=0.001, l2_lambda=0.001\n",
    ")\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc, label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training and Test Accuracy\")\n",
    "plt.legend()\n",
    "# Plot Gradient Norms\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, grad_norms, 'r-', label='Avg Gradient Norm')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Gradient Norm\")\n",
    "plt.title(\"Average Gradient Norm per Epoch\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a0057-fa19-4da1-ade3-b8b9ae839505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
