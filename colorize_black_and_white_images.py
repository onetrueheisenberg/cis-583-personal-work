# -*- coding: utf-8 -*-
"""Colorize black and white images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CfHeuU0ZS4ZOzY3CYxJdNCWlnsOdtV96

To do List

1.   CNN - Based Autoencoder, LAB - Pranavi
2.   GAN - Based Approach - Rahul
3.   U - Net - Based Colorization,Live Photo conversion to color - Sindhuja
4.   Error Analysis and Retraining using Hyperparameter tuning - Sundar
"""

!pip install kaggle

from google.colab import files
files.upload()  # Manually upload kaggle.json

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d theblackmamba31/landscape-image-colorization

import zipfile

dataset_zip = "landscape-image-colorization.zip"
with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
    zip_ref.extractall("landscape_dataset")

import os

dataset_path = "landscape_dataset/landscape Images"  # Check inside "landscape Images"
print("Files in 'landscape Images':", os.listdir(dataset_path))

gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")

if os.path.exists(gray_folder):
    print(f"Gray folder found! Total images: {len(os.listdir(gray_folder))}")
else:
    print(f"Gray folder NOT found at {gray_folder}")

if os.path.exists(color_folder):
    print(f"Color folder found! Total images: {len(os.listdir(color_folder))}")
else:
    print(f"Color folder NOT found at {color_folder}")

"""**To check Image sizes,aspect ratios and Descriptive Statistics**"""

import cv2
import pandas as pd
import os

# Dataset paths
folders = [gray_folder, color_folder]
image_shapes = []

# Loop through each folder and read images
for folder in folders:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                h, w = img.shape[:2]  # Height, Width
                c = 1 if len(img.shape) == 2 else img.shape[2]  # 1 for grayscale, 3 for color
                image_shapes.append((h, w, c))

# Convert to DataFrame and compute aspect ratio
df_shapes = pd.DataFrame(image_shapes, columns=["Height", "Width", "Channels"])
df_shapes["Aspect Ratio"] = df_shapes["Width"] / df_shapes["Height"]

# Print summary
print(df_shapes.head())
print("\nDescriptive Statistics:")
print(df_shapes.describe())

"""**Histogram of Image Width and Height and Aspect Ratio Distribution**"""

import seaborn as sns
import matplotlib.pyplot as plt

# Create DataFrame
df_shapes = pd.DataFrame(image_shapes, columns=["Height", "Width", "Channels"])
df_shapes["Aspect Ratio"] = df_shapes["Width"] / df_shapes["Height"]

# **1. Histogram of Image Width and Height**
plt.figure(figsize=(7, 5))
plt.hist(df_shapes["Width"], bins=20, alpha=0.6, label="Width", color='blue')
plt.hist(df_shapes["Height"], bins=20, alpha=0.6, label="Height", color='red')
plt.xlabel("Pixels")
plt.ylabel("Frequency")
plt.title("Image Width & Height Distribution")
plt.legend()
plt.show()

#  **2. Aspect Ratio Distribution**
plt.figure(figsize=(7, 4))
plt.hist(df_shapes["Aspect Ratio"], bins=20, color='green', alpha=0.7)
plt.xlabel("Aspect Ratio (Width/Height)")
plt.ylabel("Frequency")
plt.title("Aspect Ratio Distribution")
plt.show()

"""**Visualizing the samples **"""

import random
import matplotlib.pyplot as plt

def show_sample_images(folder, title, num_samples=5):
    if not os.path.exists(folder):
        print(f"Error: Folder {folder} does not exist.")
        return

    # Get all valid image files
    image_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.png', '.jpg', '.jpeg'))]

    if len(image_files) == 0:
        print(f"No images found in {folder}")
        return

    # Limit to available images if fewer than num_samples exist
    num_samples = min(num_samples, len(image_files))

    # Select random images
    sample_images = random.sample(image_files, num_samples)

    plt.figure(figsize=(12, 4))
    for i, img_path in enumerate(sample_images):
        img = cv2.imread(img_path)

        if len(img.shape) == 2:  # Grayscale image
            cmap = "gray"
        else:  # Color image
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            cmap = None

        plt.subplot(1, num_samples, i + 1)
        plt.imshow(img, cmap=cmap)
        plt.axis("off")

    plt.suptitle(title, fontsize=14)
    plt.show()

# Display 5 random images from each folder
show_sample_images(gray_folder, "Sample Grayscale Images")
show_sample_images(color_folder, "Sample Color Images")

"""RGB Channel Distribution

"""

def plot_rgb_histogram(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    colors = ('r', 'g', 'b')
    plt.figure(figsize=(7, 5))

    for i, color in enumerate(colors):
        hist = cv2.calcHist([img], [i], None, [256], [0, 256])
        plt.plot(hist, color=color)

    plt.title("RGB Channel Distribution")
    plt.xlabel("Pixel Value")
    plt.ylabel("Frequency")
    plt.show()

# Pick a random image from the color folder
if os.path.exists(color_folder):
    color_images = [os.path.join(color_folder, f) for f in os.listdir(color_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]
    if color_images:
        plot_rgb_histogram(random.choice(color_images))

"""Image Size Distribution"""

import os
import cv2
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Define source image folders
gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"

# List to store image shape details
image_shapes = []

# Process both gray and color image folders
for folder in [gray_folder, color_folder]:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path)

            if img is not None:
                h, w, c = img.shape  # Get height, width, channels
                image_shapes.append((h, w, c))
            else:
                print(f"Warning: Could not read {img_path}")  # Debugging message

# Create DataFrame only if images were processed
if len(image_shapes) > 0:
    df_shapes = pd.DataFrame(image_shapes, columns=["Height", "Width", "Channels"])

    # Check if columns exist before using them
    if "Height" in df_shapes.columns and "Width" in df_shapes.columns:
        df_shapes["Size"] = df_shapes["Height"] * df_shapes["Width"]  # Calculate Size

        # Display DataFrame structure
        print(df_shapes.head())

        # Plot the histogram of image sizes
        plt.figure(figsize=(8, 5))
        sns.histplot(df_shapes["Size"], bins=20, kde=True)
        plt.title("Distribution of Image Sizes (Pixels)")
        plt.xlabel("Image Size (Height x Width)")
        plt.ylabel("Count")
        plt.show()
    else:
        print("Error: 'Height' or 'Width' column is missing in df_shapes")
else:
    print("Error: No images found. Please check your dataset path.")

"""Mean and Standard Deviation of Images"""

import numpy as np
import cv2

means, stds = [], []

for folder in [gray_folder, color_folder]:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path) / 255.0  # Normalize
            if img is not None:
                means.append(np.mean(img))
                stds.append(np.std(img))

# Plot distribution
plt.figure(figsize=(10, 5))
sns.histplot(means, kde=True, color='blue', label="Mean Pixel Value")
sns.histplot(stds, kde=True, color='red', label="Standard Deviation")
plt.legend()
plt.title("Mean and Standard Deviation of Images")
plt.xlabel("Pixel Value")
plt.ylabel("Frequency")
plt.show()

"""**Image Brightness distribution**"""

brightness_values = []

for folder in [gray_folder, color_folder]:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                brightness_values.append(np.mean(img))

plt.figure(figsize=(8, 5))
sns.histplot(brightness_values, bins=20, kde=True)
plt.title("Brightness Distribution of Images")
plt.xlabel("Brightness (Mean Pixel Value)")
plt.ylabel("Count")
plt.show()

"""Texture Analysis using Gray-level CO-occurence Matrix"""

import skimage.feature as skf

def get_texture_features(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    glcm = skf.graycomatrix(img, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)
    contrast = skf.graycoprops(glcm, 'contrast')[0, 0]
    correlation = skf.graycoprops(glcm, 'correlation')[0, 0]
    energy = skf.graycoprops(glcm, 'energy')[0, 0]
    homogeneity = skf.graycoprops(glcm, 'homogeneity')[0, 0]

    return contrast, correlation, energy, homogeneity

# Compute texture properties for a sample image
sample_image = random.choice(os.listdir(gray_folder))
texture_features = get_texture_features(os.path.join(gray_folder, sample_image))

print(f"Texture Analysis for {sample_image}")
print(f"Contrast: {texture_features[0]:.4f}")
print(f"Correlation: {texture_features[1]:.4f}")
print(f"Energy: {texture_features[2]:.4f}")
print(f"Homogeneity: {texture_features[3]:.4f}")

"""**Orginal Image VS Augumented Image**"""

# @title Hidden
# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# # Load Original
# original_img_path = random.choice(os.listdir(color_folder))
# original_img = cv2.imread(os.path.join(color_folder, original_img_path))
# original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)

# # Instead of trying to load a potentially non-existent augmented image,
# # we'll display the original image in both subplots for this example.
# # You'll need to implement actual image augmentation logic separately.

# # Display Original in both subplots
# axes[0].imshow(original_img)
# axes[0].set_title("Original Image")
# axes[0].axis("off")

# axes[1].imshow(original_img)  # Displaying original here as a placeholder
# axes[1].set_title("Augmented Image (Placeholder)")
# axes[1].axis("off")

# plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random
# Define dataset path
dataset_path = "landscape_dataset/landscape Images"
gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")

# Load a sample grayscale and color image
gray_sample_path = os.path.join(gray_folder, os.listdir(gray_folder)[0])
color_sample_path = os.path.join(color_folder, os.listdir(color_folder)[0])

# Read grayscale and color images
gray_img = cv2.imread(gray_sample_path, cv2.IMREAD_GRAYSCALE)
color_img = cv2.imread(color_sample_path)
color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for visualization

# Display original images
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(gray_img, cmap='gray')
plt.title("Original Grayscale Image")

plt.subplot(1, 2, 2)
plt.imshow(color_img)
plt.title("Original Color Image")
plt.show()

# 1. Horizontal Flip
def horizontal_flip(img):
    return cv2.flip(img, 1)

# 2. Vertical Flip
def vertical_flip(img):
    return cv2.flip(img, 0)

# 3. Rotate by an angle
def rotate_image(img, angle=30):
    h, w = img.shape[:2]
    center = (w // 2, h // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(img, rotation_matrix, (w, h))

# 4. Adjust Brightness
def adjust_brightness(img, factor=1.5):
    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * factor, 0, 255)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

# 5. Apply Gaussian Blur
def apply_blur(img, kernel_size=5):
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)

# 6. Add Random Noise
def add_noise(img):
    noise = np.random.randint(0, 50, img.shape, dtype='uint8')
    noisy_img = cv2.add(img, noise)
    return np.clip(noisy_img, 0, 255)

# 7. Random Cropping
def random_crop(img, crop_size=50):
    h, w = img.shape[:2]
    x = random.randint(0, w - crop_size)
    y = random.randint(0, h - crop_size)
    return img[y:y + crop_size, x:x + crop_size]

# 8. Resize Image
def resize_image(img, scale=1.5):
    new_size = (int(img.shape[1] * scale), int(img.shape[0] * scale))
    return cv2.resize(img, new_size)

# Apply augmentations to the color image
aug_images = {
    "Original": color_img,
    "Horizontal Flip": horizontal_flip(color_img),
    "Vertical Flip": vertical_flip(color_img),
    "Rotated (30°)": rotate_image(color_img, 30),
    "Brightened": adjust_brightness(color_img, 1.5),
    "Blurred": apply_blur(color_img, 5),
    "With Noise": add_noise(color_img),
    "Resized (1.5x)": resize_image(color_img, 1.5),
}

# Display original vs augmented images
plt.figure(figsize=(12, 8))
for i, (title, img) in enumerate(aug_images.items()):
    plt.subplot(3, 3, i + 1)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

plt.tight_layout()
plt.show()

# Apply augmentations to the grayscale image
aug_gray_images = {
    "Original": gray_img,
    "Horizontal Flip": horizontal_flip(gray_img),
    "Vertical Flip": vertical_flip(gray_img),
    "Rotated (30°)": rotate_image(gray_img, 30),
    "Blurred": apply_blur(gray_img, 5),
    "With Noise": add_noise(gray_img),
    "Resized (1.5x)": resize_image(gray_img, 1.5),
}

# Display original vs augmented grayscale images
plt.figure(figsize=(12, 8))
for i, (title, img) in enumerate(aug_gray_images.items()):
    plt.subplot(3, 3, i + 1)
    plt.imshow(img, cmap='gray')
    plt.title(title)
    plt.axis('off')

plt.tight_layout()
plt.show()

gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
dataset_path = "landscape_dataset/landscape Images"
gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")
if not os.path.exists(gray_folder) or not os.path.exists(color_folder):
    print("Error: One or both dataset folders are missing. Please check the dataset path.")
else:
    print("Dataset folders found!")
gray_sample_name = os.listdir(gray_folder)[0]
color_sample_name = os.listdir(color_folder)[0]
gray_sample_path = os.path.join(gray_folder, gray_sample_name)
color_sample_path = os.path.join(color_folder, color_sample_name)
gray_img = cv2.imread(gray_sample_path, cv2.IMREAD_GRAYSCALE)
color_img = cv2.imread(color_sample_path)
if gray_img is None:
    print(f" Error: Grayscale image could not be loaded from {gray_sample_path}")
if color_img is None:
    print(f" Error: Color image could not be loaded from {color_sample_path}")
color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
img_lab = cv2.cvtColor(color_img, cv2.COLOR_RGB2LAB)
L, a, b = cv2.split(img_lab)
L_norm = L / 255.0
a_norm = (a - 128) / 128.0
b_norm = (b - 128) / 128.0
L_rescaled = (L_norm * 255).astype(np.uint8)
a_rescaled = ((a_norm * 128) + 128).astype(np.uint8)
b_rescaled = ((b_norm * 128) + 128).astype(np.uint8)

lab_merged = cv2.merge([L_rescaled, a_rescaled, b_rescaled])
color_reconstructed = cv2.cvtColor(lab_merged, cv2.COLOR_LAB2RGB)

plt.figure(figsize=(12, 5))

plt.subplot(1, 3, 1)
plt.imshow(L_norm, cmap="gray")
plt.title("L-Channel (Grayscale Input)")

plt.subplot(1, 3, 2)
plt.imshow(color_img)
plt.title("Original Color Image")

plt.subplot(1, 3, 3)
plt.imshow(color_reconstructed)
plt.title("Reconstructed Color Image (LAB → RGB)")

plt.show()

# @title Form1
# import torch
# from torch.utils.data import Dataset, DataLoader
# import torchvision.transforms as transforms
# import cv2
# import numpy as np
# from PIL import Image
# import os

# # Enhanced Dataset Class with Lab Color Space Conversion & Preprocessing
# class EnhancedDataset(Dataset):
#     def __init__(self, gray_root, color_root, transform=None, augment=False):
#         self.gray_images_path = [os.path.join(gray_root, img) for img in os.listdir(gray_root)]
#         self.color_images_path = [os.path.join(color_root, img) for img in os.listdir(color_root)]
#         self.transform = transform
#         self.augment = augment

#     def __len__(self):
#         return len(self.gray_images_path)

#     def preprocess_image(self, img_path):
#         # Read Image
#         img = cv2.imread(img_path)
#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

#         # Convert to Lab Color Space
#         img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
#         L, a, b = cv2.split(img_lab)

#         # Normalize
#         L = L / 255.0  # Scale L channel between [0,1]
#         a = (a - 128) / 128.0  # Scale a channel to [-1,1]
#         b = (b - 128) / 128.0  # Scale b channel to [-1,1]

#         return L, a, b

#     def __getitem__(self, idx):
#         # Load and Preprocess Images
#         L, a, b = self.preprocess_image(self.gray_images_path[idx])
#         color_img = cv2.imread(self.color_images_path[idx])
#         color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)

#         # Convert to PIL for transformations
#         gray_img = Image.fromarray((L * 255).astype(np.uint8))
#         color_img = Image.fromarray(color_img)

#         # Apply transformations
#         if self.transform:
#             gray_img = self.transform(gray_img)
#             color_img = self.transform(color_img)

#         # Apply Data Augmentation (if enabled)
#         if self.augment:
#             if torch.rand(1).item() > 0.5:
#                 gray_img = transforms.functional.hflip(gray_img)
#                 color_img = transforms.functional.hflip(color_img)

#         return gray_img, color_img

# # Define Transformations
# transform = transforms.Compose([
#     transforms.Resize((128, 128)),  # Resize while maintaining aspect ratio
#     transforms.ToTensor(),
#     transforms.Normalize(mean=0.5, std=0.5)  # Normalization
# ])

# # Create Dataset
# dataset = EnhancedDataset(gray_root="./landscape_dataset/landscape Images/gray",
#                           color_root="./landscape_dataset/landscape Images/color",
#                           transform=transform, augment=True)

# # DataLoader for Training
# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# # Display sample images after preprocessing
# import matplotlib.pyplot as plt

# gray_sample, color_sample = dataset[random.randint(1, 7128)]

# plt.figure(figsize=(8,4))
# plt.subplot(1,2,1)
# plt.imshow(gray_sample.squeeze(), cmap="gray")
# plt.title("Processed Grayscale Image")

# plt.subplot(1,2,2)
# plt.imshow(color_sample.permute(1,2,0))
# plt.title("Processed Color Image")

# plt.show()

#Rahul Work GAN

# GAN-based Image Colorization using Custom Landscape Dataset (Final Version with Feature Matching & LR Scheduler)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2
import os
import random
import matplotlib.pyplot as plt
from skimage.color import rgb2lab, lab2rgb

# -----------------------------
# Dataset Setup
# -----------------------------
class ColorizationDataset(Dataset):
    def __init__(self, gray_root, color_root, transform=None):
        self.gray_images_path = [os.path.join(gray_root, img) for img in os.listdir(gray_root) if img.endswith(('.jpg', '.png'))]
        self.color_images_path = [os.path.join(color_root, img) for img in os.listdir(color_root) if img.endswith(('.jpg', '.png'))]
        self.transform = transforms.ColorJitter(brightness=0.2, contrast=0.2)

    def __len__(self):
        return len(self.gray_images_path)

    def __getitem__(self, idx):
        color_img = cv2.imread(self.color_images_path[idx])
        color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
        color_img = cv2.resize(color_img, (128, 128))

        lab = rgb2lab(color_img).astype("float32")
        L = lab[:, :, 0] / 100.0
        ab = lab[:, :, 1:] / 128.0

        L = torch.from_numpy(L).unsqueeze(0)
        ab = torch.from_numpy(ab.transpose((2, 0, 1)))

        return L, ab

# -----------------------------
# Generator Network (U-Net style)
# -----------------------------
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, 4, 2, 1), nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.ConvTranspose2d(64, 2, 4, 2, 1), nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# -----------------------------
# Discriminator with Intermediate Feature Output
# -----------------------------
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1), nn.LeakyReLU(0.2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2))
        self.layer3 = nn.Sequential(
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2))
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256 * 16 * 16, 1),
            nn.Sigmoid())

    def forward(self, L, ab):
        x = torch.cat([L, ab], dim=1)
        f1 = self.layer1(x)
        f2 = self.layer2(f1)
        f3 = self.layer3(f2)
        out = self.classifier(f3)
        return out, f2  # Return intermediate features for feature matching

# -----------------------------
# Training Configuration
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
G = Generator().to(device)
D = Discriminator().to(device)

criterion_GAN = nn.MSELoss()
criterion_L1 = nn.L1Loss()

optimizer_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))
optimizer_D = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))

scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.5)
scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.5)

gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"
dataset = ColorizationDataset(gray_folder, color_folder)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# -----------------------------
# Training Loop
# -----------------------------
epochs = 20
for epoch in range(epochs):
    for i, (L, ab) in enumerate(dataloader):
        L, ab = L.to(device), ab.to(device)

        real_labels = torch.full((L.size(0), 1), 0.9, device=device)
        fake_labels = torch.zeros((L.size(0), 1), device=device)

        # === Train Discriminator ===
        fake_ab = G(L).detach()
        outputs_fake, _ = D(L.detach(), fake_ab)
        outputs_real, _ = D(L.detach(), ab.detach())

        d_loss_fake = criterion_GAN(outputs_fake, fake_labels)
        d_loss_real = criterion_GAN(outputs_real, real_labels)
        d_loss = d_loss_real + d_loss_fake

        optimizer_D.zero_grad()
        d_loss.backward()
        optimizer_D.step()

        # === Train Generator ===
        fake_ab = G(L)
        outputs_fake, fake_feat = D(L, fake_ab)

        with torch.no_grad():
            _, real_feat = D(L, ab)

        g_loss_adv = criterion_GAN(outputs_fake, real_labels)
        g_loss_l1 = criterion_L1(fake_ab, ab)
        g_loss_fm = criterion_L1(fake_feat, real_feat)
        g_loss = g_loss_adv + 100 * g_loss_l1 + 10 * g_loss_fm

        optimizer_G.zero_grad()
        g_loss.backward()
        optimizer_G.step()

        if i % 20 == 0:
            print(f"Epoch [{epoch + 1}/{epochs}], Step [{i}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}")

    scheduler_G.step()
    scheduler_D.step()

# -----------------------------
# Inference Function with Save Option
# -----------------------------
def colorize_image(img_path, save_path=None):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (128, 128))
    lab = rgb2lab(img).astype("float32")
    L = lab[:, :, 0] / 100.0

    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).to(device)
    with torch.no_grad():
        fake_ab = G(L_tensor).cpu().squeeze(0).numpy().transpose(1, 2, 0)

    fake_ab = fake_ab * 128
    L = L * 100
    color_lab = np.concatenate((L[:, :, np.newaxis], fake_ab), axis=2)
    color_rgb = lab2rgb(color_lab.astype(np.float64))

    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.imshow(L, cmap="gray")
    plt.title("Input Grayscale")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(color_rgb)
    plt.title("Colorized Output")
    plt.axis("off")
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path)
    plt.show()

# Define test image paths
test_images = [
    "/content/landscape_dataset/landscape Images/gray/0.jpg",
    "/content/landscape_dataset/landscape Images/gray/1.jpg"
]

# Display results (no saving)
for img_path in test_images:
    colorize_image(img_path)  # Will display side-by-side result

from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

def evaluate_generated_image(generated_img, ground_truth_img):
    ground_truth_img = cv2.resize(ground_truth_img, (generated_img.shape[1], generated_img.shape[0]))
    generated_img = np.clip(generated_img, 0, 1).astype(np.float32)
    ground_truth_img = np.clip(ground_truth_img / 255.0, 0, 1).astype(np.float32)
    psnr_score = psnr(ground_truth_img, generated_img, data_range=1.0)
    ssim_score = ssim(ground_truth_img, generated_img, channel_axis=-1, data_range=1.0)
    return psnr_score, ssim_score

def colorize_and_evaluate(gray_path, color_path):
    gray_img = cv2.imread(gray_path, cv2.IMREAD_GRAYSCALE)
    color_img = cv2.imread(color_path)
    color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
    color_img = cv2.resize(color_img, (128, 128))

    L = rgb2lab(color_img)[:, :, 0] / 100.0
    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device)

    with torch.no_grad():
        fake_ab = G(L_tensor).cpu().squeeze(0).numpy().transpose(1, 2, 0)

    fake_ab = fake_ab * 128
    L = L * 100
    fake_lab = np.concatenate((L[:, :, np.newaxis], fake_ab), axis=2)
    fake_rgb = lab2rgb(fake_lab.astype(np.float64))

    psnr_score, ssim_score = evaluate_generated_image(fake_rgb, color_img)

    plt.figure(figsize=(10, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(gray_img, cmap='gray')
    plt.title("Grayscale")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(color_img)
    plt.title("Ground Truth")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(fake_rgb)
    plt.title("Generated")
    plt.axis("off")
    plt.tight_layout()
    plt.show()

    print(f"PSNR: {psnr_score:.2f} dB, SSIM: {ssim_score:.4f}")

# Define test image IDs and folders
test_ids = [0, 1]
gray_folder = "/content/landscape_dataset/landscape Images/gray"
color_folder = "/content/landscape_dataset/landscape Images/color"

# Loop through test images, display & evaluate
for idx in test_ids:
    gray_path = f"{gray_folder}/{idx}.jpg"
    color_path = f"{color_folder}/{idx}.jpg"
    print(f"\nEvaluating image {idx}.jpg:")
    colorize_and_evaluate(gray_path, color_path)