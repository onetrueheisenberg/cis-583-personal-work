# -*- coding: utf-8 -*-
"""Colorize black and white images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CfHeuU0ZS4ZOzY3CYxJdNCWlnsOdtV96

To do List

1.   CNN - Based Autoencoder, LAB - Pranavi
2.   GAN - Based Approach - Rahul
3.   U - Net - Based Colorization,Live Photo conversion to color - Sindhuja
4.   Error Analysis and Retraining using Hyperparameter tuning - Sundar
"""

!pip install kaggle

from google.colab import files
files.upload()  # Manually upload kaggle.json

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d theblackmamba31/landscape-image-colorization

import zipfile

dataset_zip = "landscape-image-colorization.zip"
with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
    zip_ref.extractall("landscape_dataset")

import os

dataset_path = "landscape_dataset/landscape Images"  # Check inside "landscape Images"
print("Files in 'landscape Images':", os.listdir(dataset_path))

gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")

if os.path.exists(gray_folder):
    print(f"Gray folder found! Total images: {len(os.listdir(gray_folder))}")
else:
    print(f"Gray folder NOT found at {gray_folder}")

if os.path.exists(color_folder):
    print(f"Color folder found! Total images: {len(os.listdir(color_folder))}")
else:
    print(f"Color folder NOT found at {color_folder}")

"""**To check Image sizes,aspect ratios and Descriptive Statistics**"""

# @title To check Image sizes,aspect ratios and Descriptive Statistics
import cv2
import pandas as pd
import os

# Dataset paths
folders = [gray_folder, color_folder]
image_shapes = []

# Loop through each folder and read images
for folder in folders:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                h, w = img.shape[:2]  # Height, Width
                c = 1 if len(img.shape) == 2 else img.shape[2]  # 1 for grayscale, 3 for color
                image_shapes.append((h, w, c))

# Convert to DataFrame and compute aspect ratio
df_shapes = pd.DataFrame(image_shapes, columns=["Height", "Width", "Channels"])
df_shapes["Aspect Ratio"] = df_shapes["Width"] / df_shapes["Height"]

# Print summary
print(df_shapes.head())
print("\nDescriptive Statistics:")
print(df_shapes.describe())

"""**Histogram of Image Width and Height and Aspect Ratio Distribution**"""

# @title Histogram of Image Width and Height and Aspect Ratio Distribution

import seaborn as sns
import matplotlib.pyplot as plt

# Create DataFrame
df_shapes = pd.DataFrame(image_shapes, columns=["Height", "Width", "Channels"])
df_shapes["Aspect Ratio"] = df_shapes["Width"] / df_shapes["Height"]

# **1. Histogram of Image Width and Height**
plt.figure(figsize=(7, 5))
plt.hist(df_shapes["Width"], bins=20, alpha=0.6, label="Width", color='blue')
plt.hist(df_shapes["Height"], bins=20, alpha=0.6, label="Height", color='red')
plt.xlabel("Pixels")
plt.ylabel("Frequency")
plt.title("Image Width & Height Distribution")
plt.legend()
plt.show()

#  **2. Aspect Ratio Distribution**
plt.figure(figsize=(7, 4))
plt.hist(df_shapes["Aspect Ratio"], bins=20, color='green', alpha=0.7)
plt.xlabel("Aspect Ratio (Width/Height)")
plt.ylabel("Frequency")
plt.title("Aspect Ratio Distribution")
plt.show()

"""**Visualizing the samples **"""

# @title Visualizing the samples
import random
import matplotlib.pyplot as plt

def show_sample_images(folder, title, num_samples=5):
    if not os.path.exists(folder):
        print(f"Error: Folder {folder} does not exist.")
        return

    # Get all valid image files
    image_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.png', '.jpg', '.jpeg'))]

    if len(image_files) == 0:
        print(f"No images found in {folder}")
        return

    # Limit to available images if fewer than num_samples exist
    num_samples = min(num_samples, len(image_files))

    # Select random images
    sample_images = random.sample(image_files, num_samples)

    plt.figure(figsize=(12, 4))
    for i, img_path in enumerate(sample_images):
        img = cv2.imread(img_path)

        if len(img.shape) == 2:  # Grayscale image
            cmap = "gray"
        else:  # Color image
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            cmap = None

        plt.subplot(1, num_samples, i + 1)
        plt.imshow(img, cmap=cmap)
        plt.axis("off")

    plt.suptitle(title, fontsize=14)
    plt.show()

# Display 5 random images from each folder
show_sample_images(gray_folder, "Sample Grayscale Images")
show_sample_images(color_folder, "Sample Color Images")

"""RGB Channel Distribution

"""

# @title RGB Channel Distribution
def plot_rgb_histogram(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    colors = ('r', 'g', 'b')
    plt.figure(figsize=(7, 5))

    for i, color in enumerate(colors):
        hist = cv2.calcHist([img], [i], None, [256], [0, 256])
        plt.plot(hist, color=color)

    plt.title("RGB Channel Distribution")
    plt.xlabel("Pixel Value")
    plt.ylabel("Frequency")
    plt.show()

# Pick a random image from the color folder
if os.path.exists(color_folder):
    color_images = [os.path.join(color_folder, f) for f in os.listdir(color_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]
    if color_images:
        plot_rgb_histogram(random.choice(color_images))

"""Image Size Distribution"""

# @title Image Size Distribution
import os
import cv2
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Define source image folders
gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"

# List to store image shape details
image_shapes = []

# Process both gray and color image folders
for folder in [gray_folder, color_folder]:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path)

            if img is not None:
                h, w, c = img.shape  # Get height, width, channels
                image_shapes.append((h, w, c))
            else:
                print(f"Warning: Could not read {img_path}")  # Debugging message

# Create DataFrame only if images were processed
if len(image_shapes) > 0:
    df_shapes = pd.DataFrame(image_shapes, columns=["Height", "Width", "Channels"])

    # Check if columns exist before using them
    if "Height" in df_shapes.columns and "Width" in df_shapes.columns:
        df_shapes["Size"] = df_shapes["Height"] * df_shapes["Width"]  # Calculate Size

        # Display DataFrame structure
        print(df_shapes.head())

        # Plot the histogram of image sizes
        plt.figure(figsize=(8, 5))
        sns.histplot(df_shapes["Size"], bins=20, kde=True)
        plt.title("Distribution of Image Sizes (Pixels)")
        plt.xlabel("Image Size (Height x Width)")
        plt.ylabel("Count")
        plt.show()
    else:
        print("Error: 'Height' or 'Width' column is missing in df_shapes")
else:
    print("Error: No images found. Please check your dataset path.")

"""Mean and Standard Deviation of Images"""

# @title Mean and Standard Deviation of Images
import numpy as np
import cv2

means, stds = [], []

for folder in [gray_folder, color_folder]:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path) / 255.0  # Normalize
            if img is not None:
                means.append(np.mean(img))
                stds.append(np.std(img))

# Plot distribution
plt.figure(figsize=(10, 5))
sns.histplot(means, kde=True, color='blue', label="Mean Pixel Value")
sns.histplot(stds, kde=True, color='red', label="Standard Deviation")
plt.legend()
plt.title("Mean and Standard Deviation of Images")
plt.xlabel("Pixel Value")
plt.ylabel("Frequency")
plt.show()

"""**Image Brightness distribution**"""

# @title Image Brightness distribution
brightness_values = []

for folder in [gray_folder, color_folder]:
    if os.path.exists(folder):
        for img_name in os.listdir(folder):
            img_path = os.path.join(folder, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                brightness_values.append(np.mean(img))

plt.figure(figsize=(8, 5))
sns.histplot(brightness_values, bins=20, kde=True)
plt.title("Brightness Distribution of Images")
plt.xlabel("Brightness (Mean Pixel Value)")
plt.ylabel("Count")
plt.show()

"""Texture Analysis using Gray-level CO-occurence Matrix"""

# @title Texture Analysis using Gray-level CO-occurence Matrix
import skimage.feature as skf

def get_texture_features(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    glcm = skf.graycomatrix(img, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)
    contrast = skf.graycoprops(glcm, 'contrast')[0, 0]
    correlation = skf.graycoprops(glcm, 'correlation')[0, 0]
    energy = skf.graycoprops(glcm, 'energy')[0, 0]
    homogeneity = skf.graycoprops(glcm, 'homogeneity')[0, 0]

    return contrast, correlation, energy, homogeneity

# Compute texture properties for a sample image
sample_image = random.choice(os.listdir(gray_folder))
texture_features = get_texture_features(os.path.join(gray_folder, sample_image))

print(f"Texture Analysis for {sample_image}")
print(f"Contrast: {texture_features[0]:.4f}")
print(f"Correlation: {texture_features[1]:.4f}")
print(f"Energy: {texture_features[2]:.4f}")
print(f"Homogeneity: {texture_features[3]:.4f}")

"""**Orginal Image VS Augumented Image**"""

# @title Hidden
# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# # Load Original
# original_img_path = random.choice(os.listdir(color_folder))
# original_img = cv2.imread(os.path.join(color_folder, original_img_path))
# original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)

# # Instead of trying to load a potentially non-existent augmented image,
# # we'll display the original image in both subplots for this example.
# # You'll need to implement actual image augmentation logic separately.

# # Display Original in both subplots
# axes[0].imshow(original_img)
# axes[0].set_title("Original Image")
# axes[0].axis("off")

# axes[1].imshow(original_img)  # Displaying original here as a placeholder
# axes[1].set_title("Augmented Image (Placeholder)")
# axes[1].axis("off")

# plt.show()

# @title Image flip
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random
# Define dataset path
dataset_path = "landscape_dataset/landscape Images"
gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")

# Load a sample grayscale and color image
gray_sample_path = os.path.join(gray_folder, os.listdir(gray_folder)[0])
color_sample_path = os.path.join(color_folder, os.listdir(color_folder)[0])

# Read grayscale and color images
gray_img = cv2.imread(gray_sample_path, cv2.IMREAD_GRAYSCALE)
color_img = cv2.imread(color_sample_path)
color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for visualization

# Display original images
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(gray_img, cmap='gray')
plt.title("Original Grayscale Image")

plt.subplot(1, 2, 2)
plt.imshow(color_img)
plt.title("Original Color Image")
plt.show()

# 1. Horizontal Flip
def horizontal_flip(img):
    return cv2.flip(img, 1)

# 2. Vertical Flip
def vertical_flip(img):
    return cv2.flip(img, 0)

# 3. Rotate by an angle
def rotate_image(img, angle=30):
    h, w = img.shape[:2]
    center = (w // 2, h // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(img, rotation_matrix, (w, h))

# 4. Adjust Brightness
def adjust_brightness(img, factor=1.5):
    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * factor, 0, 255)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

# 5. Apply Gaussian Blur
def apply_blur(img, kernel_size=5):
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)

# 6. Add Random Noise
def add_noise(img):
    noise = np.random.randint(0, 50, img.shape, dtype='uint8')
    noisy_img = cv2.add(img, noise)
    return np.clip(noisy_img, 0, 255)

# 7. Random Cropping
def random_crop(img, crop_size=50):
    h, w = img.shape[:2]
    x = random.randint(0, w - crop_size)
    y = random.randint(0, h - crop_size)
    return img[y:y + crop_size, x:x + crop_size]

# 8. Resize Image
def resize_image(img, scale=1.5):
    new_size = (int(img.shape[1] * scale), int(img.shape[0] * scale))
    return cv2.resize(img, new_size)

# Apply augmentations to the color image
aug_images = {
    "Original": color_img,
    "Horizontal Flip": horizontal_flip(color_img),
    "Vertical Flip": vertical_flip(color_img),
    "Rotated (30°)": rotate_image(color_img, 30),
    "Brightened": adjust_brightness(color_img, 1.5),
    "Blurred": apply_blur(color_img, 5),
    "With Noise": add_noise(color_img),
    "Resized (1.5x)": resize_image(color_img, 1.5),
}

# Display original vs augmented images
plt.figure(figsize=(12, 8))
for i, (title, img) in enumerate(aug_images.items()):
    plt.subplot(3, 3, i + 1)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

plt.tight_layout()
plt.show()

# Apply augmentations to the grayscale image
aug_gray_images = {
    "Original": gray_img,
    "Horizontal Flip": horizontal_flip(gray_img),
    "Vertical Flip": vertical_flip(gray_img),
    "Rotated (30°)": rotate_image(gray_img, 30),
    "Blurred": apply_blur(gray_img, 5),
    "With Noise": add_noise(gray_img),
    "Resized (1.5x)": resize_image(gray_img, 1.5),
}

# Display original vs augmented grayscale images
plt.figure(figsize=(12, 8))
for i, (title, img) in enumerate(aug_gray_images.items()):
    plt.subplot(3, 3, i + 1)
    plt.imshow(img, cmap='gray')
    plt.title(title)
    plt.axis('off')

plt.tight_layout()
plt.show()

# @title Dataset path
gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"

# @title Reconstructed
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
dataset_path = "landscape_dataset/landscape Images"
gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")
if not os.path.exists(gray_folder) or not os.path.exists(color_folder):
    print("Error: One or both dataset folders are missing. Please check the dataset path.")
else:
    print("Dataset folders found!")
gray_sample_name = os.listdir(gray_folder)[0]
color_sample_name = os.listdir(color_folder)[0]
gray_sample_path = os.path.join(gray_folder, gray_sample_name)
color_sample_path = os.path.join(color_folder, color_sample_name)
gray_img = cv2.imread(gray_sample_path, cv2.IMREAD_GRAYSCALE)
color_img = cv2.imread(color_sample_path)
if gray_img is None:
    print(f" Error: Grayscale image could not be loaded from {gray_sample_path}")
if color_img is None:
    print(f" Error: Color image could not be loaded from {color_sample_path}")
color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
img_lab = cv2.cvtColor(color_img, cv2.COLOR_RGB2LAB)
L, a, b = cv2.split(img_lab)
L_norm = L / 255.0
a_norm = (a - 128) / 128.0
b_norm = (b - 128) / 128.0
L_rescaled = (L_norm * 255).astype(np.uint8)
a_rescaled = ((a_norm * 128) + 128).astype(np.uint8)
b_rescaled = ((b_norm * 128) + 128).astype(np.uint8)

lab_merged = cv2.merge([L_rescaled, a_rescaled, b_rescaled])
color_reconstructed = cv2.cvtColor(lab_merged, cv2.COLOR_LAB2RGB)

plt.figure(figsize=(12, 5))

plt.subplot(1, 3, 1)
plt.imshow(L_norm, cmap="gray")
plt.title("L-Channel (Grayscale Input)")

plt.subplot(1, 3, 2)
plt.imshow(color_img)
plt.title("Original Color Image")

plt.subplot(1, 3, 3)
plt.imshow(color_reconstructed)
plt.title("Reconstructed Color Image (LAB → RGB)")

plt.show()

# @title Form1
# import torch
# from torch.utils.data import Dataset, DataLoader
# import torchvision.transforms as transforms
# import cv2
# import numpy as np
# from PIL import Image
# import os

# # Enhanced Dataset Class with Lab Color Space Conversion & Preprocessing
# class EnhancedDataset(Dataset):
#     def __init__(self, gray_root, color_root, transform=None, augment=False):
#         self.gray_images_path = [os.path.join(gray_root, img) for img in os.listdir(gray_root)]
#         self.color_images_path = [os.path.join(color_root, img) for img in os.listdir(color_root)]
#         self.transform = transform
#         self.augment = augment

#     def __len__(self):
#         return len(self.gray_images_path)

#     def preprocess_image(self, img_path):
#         # Read Image
#         img = cv2.imread(img_path)
#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

#         # Convert to Lab Color Space
#         img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
#         L, a, b = cv2.split(img_lab)

#         # Normalize
#         L = L / 255.0  # Scale L channel between [0,1]
#         a = (a - 128) / 128.0  # Scale a channel to [-1,1]
#         b = (b - 128) / 128.0  # Scale b channel to [-1,1]

#         return L, a, b

#     def __getitem__(self, idx):
#         # Load and Preprocess Images
#         L, a, b = self.preprocess_image(self.gray_images_path[idx])
#         color_img = cv2.imread(self.color_images_path[idx])
#         color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)

#         # Convert to PIL for transformations
#         gray_img = Image.fromarray((L * 255).astype(np.uint8))
#         color_img = Image.fromarray(color_img)

#         # Apply transformations
#         if self.transform:
#             gray_img = self.transform(gray_img)
#             color_img = self.transform(color_img)

#         # Apply Data Augmentation (if enabled)
#         if self.augment:
#             if torch.rand(1).item() > 0.5:
#                 gray_img = transforms.functional.hflip(gray_img)
#                 color_img = transforms.functional.hflip(color_img)

#         return gray_img, color_img

# # Define Transformations
# transform = transforms.Compose([
#     transforms.Resize((128, 128)),  # Resize while maintaining aspect ratio
#     transforms.ToTensor(),
#     transforms.Normalize(mean=0.5, std=0.5)  # Normalization
# ])

# # Create Dataset
# dataset = EnhancedDataset(gray_root="./landscape_dataset/landscape Images/gray",
#                           color_root="./landscape_dataset/landscape Images/color",
#                           transform=transform, augment=True)

# # DataLoader for Training
# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# # Display sample images after preprocessing
# import matplotlib.pyplot as plt

# gray_sample, color_sample = dataset[random.randint(1, 7128)]

# plt.figure(figsize=(8,4))
# plt.subplot(1,2,1)
# plt.imshow(gray_sample.squeeze(), cmap="gray")
# plt.title("Processed Grayscale Image")

# plt.subplot(1,2,2)
# plt.imshow(color_sample.permute(1,2,0))
# plt.title("Processed Color Image")

# plt.show()

"""**GAN-based Image Colorization using Custom Landscape Dataset**"""

# GAN-based Image Colorization using Custom Landscape Dataset (Final Version with Feature Matching & LR Scheduler)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2
import os
import random
import matplotlib.pyplot as plt
from skimage.color import rgb2lab, lab2rgb

# -----------------------------
# Dataset Setup
# -----------------------------
class ColorizationDataset(Dataset):
    def __init__(self, gray_root, color_root, transform=None):
        self.gray_images_path = [os.path.join(gray_root, img) for img in os.listdir(gray_root) if img.endswith(('.jpg', '.png'))]
        self.color_images_path = [os.path.join(color_root, img) for img in os.listdir(color_root) if img.endswith(('.jpg', '.png'))]
        self.transform = transforms.ColorJitter(brightness=0.2, contrast=0.2)

    def __len__(self):
        return len(self.gray_images_path)

    def __getitem__(self, idx):
        color_img = cv2.imread(self.color_images_path[idx])
        color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
        color_img = cv2.resize(color_img, (128, 128))

        lab = rgb2lab(color_img).astype("float32")
        L = lab[:, :, 0] / 100.0
        ab = lab[:, :, 1:] / 128.0

        L = torch.from_numpy(L).unsqueeze(0)
        ab = torch.from_numpy(ab.transpose((2, 0, 1)))

        return L, ab

# -----------------------------
# Generator Network (U-Net style)
# -----------------------------
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, 4, 2, 1), nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.ConvTranspose2d(64, 2, 4, 2, 1), nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# -----------------------------
# Discriminator with Intermediate Feature Output
# -----------------------------
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1), nn.LeakyReLU(0.2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2))
        self.layer3 = nn.Sequential(
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2))
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256 * 16 * 16, 1),
            nn.Sigmoid())

    def forward(self, L, ab):
        x = torch.cat([L, ab], dim=1)
        f1 = self.layer1(x)
        f2 = self.layer2(f1)
        f3 = self.layer3(f2)
        out = self.classifier(f3)
        return out, f2  # Return intermediate features for feature matching

# -----------------------------
# Training Configuration
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
G = Generator().to(device)
D = Discriminator().to(device)

criterion_GAN = nn.BCELoss()
criterion_L1 = nn.L1Loss()

optimizer_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))
optimizer_D = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))

scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.5)
scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.5)

gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"
dataset = ColorizationDataset(gray_folder, color_folder)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# -----------------------------
# Training Loop
# -----------------------------
epochs = 20
for epoch in range(epochs):
    for i, (L, ab) in enumerate(dataloader):
        L, ab = L.to(device), ab.to(device)

        real_labels = torch.full((L.size(0), 1), 0.9, device=device)
        fake_labels = torch.zeros((L.size(0), 1), device=device)

        # === Train Discriminator ===
        fake_ab = G(L).detach()
        outputs_fake, _ = D(L.detach(), fake_ab)
        outputs_real, _ = D(L.detach(), ab.detach())

        d_loss_fake = criterion_GAN(outputs_fake, fake_labels)
        d_loss_real = criterion_GAN(outputs_real, real_labels)
        d_loss = d_loss_real + d_loss_fake

        optimizer_D.zero_grad()
        d_loss.backward()
        optimizer_D.step()

        # === Train Generator ===
        fake_ab = G(L)
        outputs_fake, fake_feat = D(L, fake_ab)

        with torch.no_grad():
            _, real_feat = D(L, ab)

        g_loss_adv = criterion_GAN(outputs_fake, real_labels)
        g_loss_l1 = criterion_L1(fake_ab, ab)
        g_loss_fm = criterion_L1(fake_feat, real_feat)
        g_loss = g_loss_adv + 100 * g_loss_l1 + 10 * g_loss_fm

        optimizer_G.zero_grad()
        g_loss.backward()
        optimizer_G.step()

        if i % 20 == 0:
            print(f"Epoch [{epoch + 1}/{epochs}], Step [{i}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}")

    scheduler_G.step()
    scheduler_D.step()

# -----------------------------
# Inference Function with Save Option
# -----------------------------
def colorize_image(img_path, save_path=None):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (128, 128))
    lab = rgb2lab(img).astype("float32")
    L = lab[:, :, 0] / 100.0

    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).to(device)
    with torch.no_grad():
        fake_ab = G(L_tensor).cpu().squeeze(0).numpy().transpose(1, 2, 0)

    fake_ab = fake_ab * 128
    L = L * 100
    color_lab = np.concatenate((L[:, :, np.newaxis], fake_ab), axis=2)
    color_rgb = lab2rgb(color_lab.astype(np.float64))

    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.imshow(L, cmap="gray")
    plt.title("Input Grayscale")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(color_rgb)
    plt.title("Colorized Output")
    plt.axis("off")
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path)
    plt.show()

# Define test image paths
test_images = [
    "/content/landscape_dataset/landscape Images/gray/0.jpg",
    "/content/landscape_dataset/landscape Images/gray/1.jpg"
]

# Display results (no saving)
for img_path in test_images:
    colorize_image(img_path)  # Will display side-by-side result

from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

def evaluate_generated_image(generated_img, ground_truth_img):
    ground_truth_img = cv2.resize(ground_truth_img, (generated_img.shape[1], generated_img.shape[0]))
    generated_img = np.clip(generated_img, 0, 1).astype(np.float32)
    ground_truth_img = np.clip(ground_truth_img / 255.0, 0, 1).astype(np.float32)
    psnr_score = psnr(ground_truth_img, generated_img, data_range=1.0)
    ssim_score = ssim(ground_truth_img, generated_img, channel_axis=-1, data_range=1.0)
    return psnr_score, ssim_score

def colorize_and_evaluate(gray_path, color_path):
    gray_img = cv2.imread(gray_path, cv2.IMREAD_GRAYSCALE)
    color_img = cv2.imread(color_path)
    color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
    color_img = cv2.resize(color_img, (128, 128))

    L = rgb2lab(color_img)[:, :, 0] / 100.0
    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device)

    with torch.no_grad():
        fake_ab = G(L_tensor).cpu().squeeze(0).numpy().transpose(1, 2, 0)

    fake_ab = fake_ab * 128
    L = L * 100
    fake_lab = np.concatenate((L[:, :, np.newaxis], fake_ab), axis=2)
    fake_rgb = lab2rgb(fake_lab.astype(np.float64))

    psnr_score, ssim_score = evaluate_generated_image(fake_rgb, color_img)

    plt.figure(figsize=(10, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(gray_img, cmap='gray')
    plt.title("Grayscale")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(color_img)
    plt.title("Ground Truth")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(fake_rgb)
    plt.title("Generated")
    plt.axis("off")
    plt.tight_layout()
    plt.show()

    print(f"PSNR: {psnr_score:.2f} dB, SSIM: {ssim_score:.4f}")

# Define test image IDs and folders
test_ids = [0, 1]
gray_folder = "/content/landscape_dataset/landscape Images/gray"
color_folder = "/content/landscape_dataset/landscape Images/color"

# Loop through test images, display & evaluate
for idx in test_ids:
    gray_path = f"{gray_folder}/{idx}.jpg"
    color_path = f"{color_folder}/{idx}.jpg"
    print(f"\nEvaluating image {idx}.jpg:")
    colorize_and_evaluate(gray_path, color_path)

"""CNN"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from skimage.metrics import structural_similarity as ssim


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# dataset
class LandscapeColorizationDataset(Dataset):
    def __init__(self, gray_folder, color_folder, transform=None):
        self.gray_folder = gray_folder
        self.color_folder = color_folder
        self.gray_images = sorted(os.listdir(gray_folder))
        self.color_images = sorted(os.listdir(color_folder))
        self.transform = transform

    def __len__(self):
        return len(self.gray_images)

    def __getitem__(self, idx):
        gray_path = os.path.join(self.gray_folder, self.gray_images[idx])
        color_path = os.path.join(self.color_folder, self.color_images[idx])

        gray_image = Image.open(gray_path).convert("L")
        color_image = Image.open(color_path).convert("RGB")

        if self.transform:
            gray_image = self.transform(gray_image)
            color_image = self.transform(color_image)

        return gray_image, color_image

# dataset path
dataset_path = "landscape_dataset/landscape Images"
gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

dataset = LandscapeColorizationDataset(gray_folder, color_folder, transform)

# splitting data
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

print(f"Total images: {len(dataset)}")
print(f"Training set: {len(train_dataset)} images")
print(f"Test set: {len(test_dataset)} images")

#  AUTOENCODER MODEL
class ColorizationAutoencoder(nn.Module):
    def __init__(self):
        super(ColorizationAutoencoder, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),   # 64x64
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 32x32
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1), # 16x16
            nn.ReLU()
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # 32x32
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 64x64
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),    # 128x128
            nn.Sigmoid()  # Output RGB in range [0,1]
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

model = ColorizationAutoencoder().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# evaualtion metrics
def compute_mae(pred, target):
    return torch.mean(torch.abs(pred - target)).item()

def compute_ssim_batch(pred, target):
    pred_np = pred.detach().cpu().numpy()
    target_np = target.detach().cpu().numpy()
    scores = []
    for i in range(pred_np.shape[0]):
        p = np.transpose(pred_np[i], (1, 2, 0))
        t = np.transpose(target_np[i], (1, 2, 0))
        scores.append(ssim(p, t, channel_axis=2, data_range=1.0))
    return np.mean(scores)

def compute_psnr(pred, target):
    pred_np = pred.detach().cpu().numpy()
    target_np = target.detach().cpu().numpy()
    mse = np.mean((pred_np - target_np) ** 2)
    return 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')

# training the model
EPOCHS = 50
mae_list, ssim_list, psnr_list = [], [], []

for epoch in range(EPOCHS):
    model.train()
    running_loss = 0.0
    total_mae, total_ssim, total_psnr = 0.0, 0.0, 0.0

    for i, (gray, color) in enumerate(train_loader):
        gray, color = gray.to(device), color.to(device)

        outputs = model(gray)
        loss = criterion(outputs, color)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        total_mae += compute_mae(outputs, color)
        total_ssim += compute_ssim_batch(outputs, color)
        total_psnr += compute_psnr(outputs, color)

    avg_loss = running_loss / len(train_loader)
    avg_mae = total_mae / len(train_loader)
    avg_ssim = total_ssim / len(train_loader)
    avg_psnr = total_psnr / len(train_loader)

    mae_list.append(avg_mae)
    ssim_list.append(avg_ssim)
    psnr_list.append(avg_psnr)

    print(f"Epoch [{epoch+1}/{EPOCHS}] Loss={avg_loss:.4f}, MAE={avg_mae:.4f}, SSIM={avg_ssim:.4f}, PSNR={avg_psnr:.2f}dB")

# test evaluation
print("\nEvaluating on test set...")
model.eval()
test_mae, test_ssim, test_psnr = 0.0, 0.0, 0.0

with torch.no_grad():
    for gray, color in test_loader:
        gray, color = gray.to(device), color.to(device)
        outputs = model(gray)
        test_mae += compute_mae(outputs, color)
        test_ssim += compute_ssim_batch(outputs, color)
        test_psnr += compute_psnr(outputs, color)

avg_test_mae = test_mae / len(test_loader)
avg_test_ssim = test_ssim / len(test_loader)
avg_test_psnr = test_psnr / len(test_loader)

print(f"\nTest MAE: {avg_test_mae:.4f}")
print(f"Test SSIM: {avg_test_ssim:.4f}")
print(f"Test PSNR: {avg_test_psnr:.2f} dB")

# plots-
epochs = range(1, EPOCHS + 1)
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.plot(epochs, mae_list, 'b-', label='MAE')
plt.title('Mean Absolute Error')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.grid(True)

plt.subplot(1, 3, 2)
plt.plot(epochs, ssim_list, 'g-', label='SSIM')
plt.title('SSIM')
plt.xlabel('Epoch')
plt.ylabel('SSIM')
plt.grid(True)

plt.subplot(1, 3, 3)
plt.plot(epochs, psnr_list, 'm-', label='PSNR')
plt.title('PSNR')
plt.xlabel('Epoch')
plt.ylabel('PSNR (dB)')
plt.grid(True)

plt.tight_layout()
plt.show()

# predicitons
import torchvision.transforms.functional as TF

def show_predictions(model, loader, num_images=5):
    model.eval()
    fig, axs = plt.subplots(num_images, 3, figsize=(10, 4 * num_images))

    with torch.no_grad():
        count = 0
        for gray, color in loader:
            gray = gray.to(device)
            outputs = model(gray)

            for i in range(gray.size(0)):
                if count >= num_images:
                    break

                inp = gray[i].cpu().squeeze(0)  # (128, 128)
                pred = outputs[i].cpu().permute(1, 2, 0).numpy()
                tgt = color[i].cpu().permute(1, 2, 0).numpy()

                axs[count, 0].imshow(inp, cmap='gray')
                axs[count, 0].set_title("Grayscale Input")
                axs[count, 0].axis('off')

                axs[count, 1].imshow(tgt)
                axs[count, 1].set_title("Ground Truth Color")
                axs[count, 1].axis('off')

                axs[count, 2].imshow(pred)
                axs[count, 2].set_title("Predicted Color")
                axs[count, 2].axis('off')

                count += 1

            if count >= num_images:
                break

    plt.tight_layout()
    plt.show()

# Call the function
show_predictions(model, test_loader, num_images=5)

# Upload and predict block
from google.colab import files
from IPython.display import display

uploaded = files.upload()

for filename in uploaded.keys():
    # Preprocess the uploaded grayscale image
    img = Image.open(filename).convert("L")
    img_resized = img.resize((128, 128))
    img_tensor = transforms.ToTensor()(img_resized).unsqueeze(0).to(device)  # Shape: (1, 1, 128, 128)

    # Run model prediction
    model.eval()
    with torch.no_grad():
        output = model(img_tensor)

    # Prepare input and output for visualization
    input_image = img_tensor.squeeze(0).squeeze(0).cpu().numpy()            # (128, 128)
    output_image = output.squeeze(0).permute(1, 2, 0).cpu().numpy()         # (128, 128, 3)

    # plot
    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.imshow(input_image, cmap='gray')
    plt.title("Grayscale Input")
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(output_image)
    plt.title("Predicted Color")
    plt.axis('off')

    plt.tight_layout()
    plt.show()

"""** CNN with LAB**"""

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms

from skimage.color import rgb2lab, lab2rgb
from skimage.metrics import structural_similarity as ssim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# dataset
class ColorizationDataset(Dataset):
    def __init__(self, gray_folder, color_folder, transform=None):
        self.gray_folder = gray_folder
        self.color_folder = color_folder
        self.gray_images = sorted(os.listdir(gray_folder))
        self.color_images = sorted(os.listdir(color_folder))
        self.transform = transform

    def __len__(self):
        return len(self.gray_images)

    def __getitem__(self, idx):
        gray_path = os.path.join(self.gray_folder, self.gray_images[idx])
        color_path = os.path.join(self.color_folder, self.color_images[idx])

        # Load grayscale input and RGB target
        gray_img = Image.open(gray_path).convert("L")
        color_img = Image.open(color_path).convert("RGB").resize((128, 128))

        # Convert RGB to LAB
        lab = rgb2lab(np.array(color_img)).astype("float32")
        L = lab[:, :, 0] / 100.0           # Normalize L to [0, 1]
        AB = lab[:, :, 1:] / 128.0         # Normalize AB to [-1, 1]

        if self.transform:
            gray_img = self.transform(gray_img)

        # Convert to torch tensors
        L_tensor = torch.from_numpy(L).unsqueeze(0)
        AB_tensor = torch.from_numpy(AB).permute(2, 0, 1)

        return L_tensor, AB_tensor

# dataset paths
dataset_path = "landscape_dataset/landscape Images"
gray_folder = os.path.join(dataset_path, "gray")
color_folder = os.path.join(dataset_path, "color")

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

dataset = ColorizationDataset(gray_folder, color_folder, transform)

# Split into train and test
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_data, test_data = random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_data, batch_size=16, shuffle=True)
test_loader = DataLoader(test_data, batch_size=16, shuffle=False)

# model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()

        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, 3, 2, 1),   # 128 -> 64
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, 2, 1), # 64 -> 32
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, 2, 1), # 32 -> 16
            nn.ReLU()
        )

        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1), # 16 -> 32
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 32 -> 64
            nn.ReLU(),
            nn.ConvTranspose2d(64, 2, 4, 2, 1),    # 64 -> 128
            nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

model = Autoencoder().to(device)
loss_function = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# evaluation metrics
def calc_mae(pred, target):
    return torch.mean(torch.abs(pred - target)).item()

def calc_ssim(pred, target):
    pred_np = pred.detach().cpu().numpy()
    target_np = target.detach().cpu().numpy()
    scores = []
    for i in range(pred_np.shape[0]):
        p = np.transpose(pred_np[i], (1, 2, 0))
        t = np.transpose(target_np[i], (1, 2, 0))
        scores.append(ssim(p, t, channel_axis=2, data_range=2.0))
    return np.mean(scores)

def calc_psnr(pred, target):
    pred_np = pred.detach().cpu().numpy()
    target_np = target.detach().cpu().numpy()
    mse = np.mean((pred_np - target_np) ** 2)
    return 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')

# training
EPOCHS = 40
mae_history, ssim_history, psnr_history = [], [], []

for epoch in range(EPOCHS):
    model.train()
    total_loss, total_mae, total_ssim, total_psnr = 0, 0, 0, 0

    for L, AB in train_loader:
        L, AB = L.to(device), AB.to(device)
        pred_AB = model(L)

        loss = loss_function(pred_AB, AB)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        total_mae += calc_mae(pred_AB, AB)
        total_ssim += calc_ssim(pred_AB, AB)
        total_psnr += calc_psnr(pred_AB, AB)

    avg_loss = total_loss / len(train_loader)
    avg_mae = total_mae / len(train_loader)
    avg_ssim = total_ssim / len(train_loader)
    avg_psnr = total_psnr / len(train_loader)

    mae_history.append(avg_mae)
    ssim_history.append(avg_ssim)
    psnr_history.append(avg_psnr)

    print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {avg_loss:.4f} | MAE: {avg_mae:.4f} | SSIM: {avg_ssim:.4f} | PSNR: {avg_psnr:.2f} dB")

# test evalution
model.eval()
test_mae, test_ssim, test_psnr = 0.0, 0.0, 0.0

with torch.no_grad():
    for L, AB in test_loader:
        L, AB = L.to(device), AB.to(device)
        pred_AB = model(L)

        test_mae += calc_mae(pred_AB, AB)
        test_ssim += calc_ssim(pred_AB, AB)
        test_psnr += calc_psnr(pred_AB, AB)

print(f"\nTest MAE: {test_mae / len(test_loader):.4f}")
print(f"Test SSIM: {test_ssim / len(test_loader):.4f}")
print(f"Test PSNR: {test_psnr / len(test_loader):.2f} dB")

# plot
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.plot(mae_history); plt.title("MAE"); plt.grid(True)
plt.subplot(1, 3, 2)
plt.plot(ssim_history); plt.title("SSIM"); plt.grid(True)
plt.subplot(1, 3, 3)
plt.plot(psnr_history); plt.title("PSNR"); plt.grid(True)
plt.tight_layout()
plt.show()

# outputs
def show_predictions(model, loader, num_images=5):
    model.eval()
    fig, axs = plt.subplots(num_images, 3, figsize=(10, 4 * num_images))

    with torch.no_grad():
        count = 0
        for L, AB in loader:
            L = L.to(device)
            pred_AB = model(L)

            for i in range(L.size(0)):
                if count >= num_images:
                    break

                # Convert LAB to RGB
                L_img = L[i].cpu().squeeze().numpy() * 100
                true_AB = AB[i].cpu().numpy().transpose(1, 2, 0) * 128
                pred_AB_np = pred_AB[i].cpu().numpy().transpose(1, 2, 0) * 128

                true_rgb = lab2rgb(np.dstack((L_img, true_AB)))
                pred_rgb = lab2rgb(np.dstack((L_img, pred_AB_np)))

                axs[count, 0].imshow(L_img, cmap='gray'); axs[count, 0].set_title("Input L")
                axs[count, 1].imshow(true_rgb); axs[count, 1].set_title("Ground Truth")
                axs[count, 2].imshow(pred_rgb); axs[count, 2].set_title("Prediction")
                for j in range(3): axs[count, j].axis('off')
                count += 1

            if count >= num_images:
                break

    plt.tight_layout()
    plt.show()

# predicitions
show_predictions(model, test_loader, num_images=5)

# ----------------- Upload and Colorize Custom Image (Fixed) -----------------
from google.colab import files
from IPython.display import display

uploaded = files.upload()

for filename in uploaded.keys():
    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        # Load and preprocess image
        img = Image.open(filename).convert("RGB").resize((128, 128))
        lab = rgb2lab(np.array(img)).astype("float32")
        L = lab[:, :, 0] / 100.0
        L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).to(device)

        # Model inference
        model.eval()
        with torch.no_grad():
            pred_AB = model(L_tensor).cpu().squeeze().numpy().transpose(1, 2, 0) * 256  # shape: (128, 128, 2)

        # Convert LAB back to RGB
        L_np = L_tensor.cpu().squeeze().numpy() * 100  # shape: (128, 128)
        lab_combined = np.dstack((L_np, pred_AB))      # shape: (128, 128, 3)
        output_rgb = lab2rgb(lab_combined)             # Convert to RGB format

        # Plot input and output
        plt.figure(figsize=(8, 4))
        plt.subplot(1, 2, 1)
        plt.imshow(L_np, cmap='gray')
        plt.title("Input Grayscale (L)")
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(output_rgb)
        plt.title("Colorized Output")
        plt.axis('off')

        plt.tight_layout()
        plt.show()
    else:
        print(f"Unsupported file type: {filename}")

"""# **U-Net**"""

import cv2
import numpy as np
import os
from tqdm import tqdm

def load_gray_color_pairs(gray_folder, color_folder, image_size=(256, 256), max_images=None):
    gray_images = sorted(os.listdir(gray_folder))
    color_images = sorted(os.listdir(color_folder))

    if max_images:
        gray_images = gray_images[:max_images]
        color_images = color_images[:max_images]

    X_L, Y_ab = [], []

    for g_file, c_file in tqdm(zip(gray_images, color_images), total=len(gray_images)):
        gray_img = cv2.imread(os.path.join(gray_folder, g_file), cv2.IMREAD_GRAYSCALE)
        color_img = cv2.imread(os.path.join(color_folder, c_file))

        if gray_img is None or color_img is None:
            continue

        gray_img = cv2.resize(gray_img, image_size)
        color_img = cv2.resize(color_img, image_size)

        lab_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2LAB)
        L = lab_img[:, :, 0] / 255.0
        ab = lab_img[:, :, 1:] / 128.0

        X_L.append(L[..., np.newaxis])   # shape: (H, W, 1)
        Y_ab.append(ab)                  # shape: (H, W, 2)

    return np.array(X_L), np.array(Y_ab)

gray_folder = "landscape_dataset/landscape Images/gray"
color_folder = "landscape_dataset/landscape Images/color"

X_L, Y_ab = load_gray_color_pairs(gray_folder, color_folder, image_size=(256, 256), max_images=1000)
print("Grayscale input shape:", X_L.shape)
print("AB color output shape:", Y_ab.shape)

import matplotlib.pyplot as plt

idx = np.random.randint(0, len(X_L))

plt.figure(figsize=(12, 4))

# Input grayscale (L)
plt.subplot(1, 2, 1)
plt.title("Grayscale (L channel)")
plt.imshow(X_L[idx].squeeze(), cmap='gray')
plt.axis('off')

# Reconstructed color image from LAB
L = X_L[idx]
ab = Y_ab[idx]
L_rescaled = L * 255.0
ab_rescaled = ab * 128.0
lab = np.concatenate((L_rescaled, ab_rescaled), axis=2).astype(np.uint8)
color_img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

plt.subplot(1, 2, 2)
plt.title("Original Color (from LAB)")
plt.imshow(color_img)
plt.axis('off')

plt.show()

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model

def build_unet(input_shape=(256, 256, 1)):
    inputs = Input(shape=input_shape)

    # Encoder
    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    p1 = MaxPooling2D()(c1)

    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)
    p2 = MaxPooling2D()(c2)

    c3 = Conv2D(256, 3, activation='relu', padding='same')(p2)
    p3 = MaxPooling2D()(c3)

    c4 = Conv2D(512, 3, activation='relu', padding='same')(p3)
    #c4 = Dropout(0.3)(c4)

    # Decoder
    u1 = UpSampling2D()(c4)
    m1 = concatenate([u1, c3])
    c5 = Conv2D(256, 3, activation='relu', padding='same')(m1)

    u2 = UpSampling2D()(c5)
    m2 = concatenate([u2, c2])
    c6 = Conv2D(128, 3, activation='relu', padding='same')(m2)

    u3 = UpSampling2D()(c6)
    m3 = concatenate([u3, c1])
    c7 = Conv2D(64, 3, activation='relu', padding='same')(m3)

    outputs = Conv2D(2, 1, activation='linear', padding='same')(c7)  # Predict AB channels

    model = Model(inputs, outputs)
    return model

from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# Split data
X_train, X_val, y_train, y_val = train_test_split(X_L, Y_ab, test_size=0.1, random_state=42)

# Build and compile
model = build_unet()
model.compile(optimizer=Adam(1e-4), loss='mae')

# Train
model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=16
)

import matplotlib.pyplot as plt

def postprocess(L, ab):
    L = L * 128.0
    ab = ab * 128.0
    lab = np.concatenate((L, ab), axis=2).astype(np.uint8)
    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

# Pick a random sample from validation set
idx = np.random.randint(0, len(X_val))

L_input = X_val[idx:idx+1]
true_ab = y_train[idx]
pred_ab = model.predict(L_input)[0]

# Combine predicted AB with L to get RGB image
colorized_img = postprocess(L_input[0], pred_ab)

# Display images
plt.figure(figsize=(12, 4))

# Grayscale Input
plt.subplot(1, 3, 1)
plt.title("Grayscale Input")
plt.imshow(L_input[0].squeeze(), cmap='gray')
plt.axis('off')

# Ground Truth Color
L_gt = L_input[0]
ab_gt = y_val[idx]
gt_img = postprocess(L_gt, ab_gt)
plt.subplot(1, 3, 2)
plt.title("Ground Truth")
plt.imshow(gt_img)
plt.axis('off')

# Predicted Color
plt.subplot(1, 3, 3)
plt.title("Colorized Output")
plt.imshow(colorized_img)
plt.axis('off')

plt.show()